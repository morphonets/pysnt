{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volumetric Quantifications\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ Outdated Content:</b> This notebook was written for an older version of SNT/PyImageJ and may be non-functional. It will be updated as PySNT development progresses. See other tutorials for current workflows.\n",
    "</div>\n",
    "\n",
    "This notebook demonstrates volumetric quantifications. It assumes you have properly [setup](./README.md) your environment and ran the introductory examples. Here's what we will accomplish:\n",
    "\n",
    "1. Generate a convex hull of the axon terminals within a specific brain region\n",
    "2. Compare the volume of this convex hull to the volume of the encompasing Allen CCF compartment.\n",
    "3. Do PCA on the point cloud of the relevant axon terminals.\n",
    "4. Visualize the results of these operations using [Reconstruction Viewer](https://imagej.net/SNT:_Reconstruction_Viewer).\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> This notebook handles computations of 3D geometries of massive reconstructions that may take several minutes to run, depending on your hardware\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "We'll need to 1) import Python modules; 2) initalize ij from local Fiji installation, and 3) import all relevant SNT (Java) classes: [AllenCompartment](https://javadoc.scijava.org/SNT/index.html?sc/fiji/snt/annotation/AllenCompartment.html), [AllenUtils](https://javadoc.scijava.org/SNT/index.html?sc/fiji/snt/annotation/AllenUtils.html), [Annotation3D](https://javadoc.scijava.org/SNT/sc/fiji/snt/viewer/Annotation3D.html), [ConvexHull2D](https://javadoc.scijava.org/SNT/index.html?sc/fiji/snt/analysis/ConvexHull2D.html), [ConvexHull3D](https://javadoc.scijava.org/SNT/index.html?sc/fiji/snt/analysis/ConvexHull3D.html), [MouseLightLoader](https://javadoc.scijava.org/SNT/index.html?sc/fiji/snt/io/MouseLightLoader.html), [PointInImage](https://javadoc.scijava.org/SNT/index.html?sc/fiji/snt/util/PointInImage.html), [Tree](https://javadoc.scijava.org/SNT/index.html?sc/fiji/snt/Tree.html), [TreeStatistics](https://javadoc.scijava.org/SNT/index.html?sc/fiji/snt/analysis/TreeStatistics.html), [Viewer3D](https://javadoc.scijava.org/SNT/index.html?sc/fiji/snt/viewer/Viewer3D.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import ijfinder\n",
    "import imagej\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "fiji_path = ijfinder.getpath().decode('utf-8')\n",
    "if os.path.isdir(fiji_path):\n",
    "    ij = imagej.init(fiji_path, mode='interactive')\n",
    "else:\n",
    "    print(\"Cannot proceed: Fiji not found!\")\n",
    "\n",
    "ij.ui().showUI()\n",
    "\n",
    "from scyjava import jimport\n",
    "AllenCompartment = jimport('sc.fiji.snt.annotation.AllenCompartment')\n",
    "AllenUtils = jimport('sc.fiji.snt.annotation.AllenUtils')\n",
    "Annotation3D = jimport('sc.fiji.snt.viewer.Annotation3D')\n",
    "ConvexHull2D = jimport('sc.fiji.snt.analysis.ConvexHull2D')\n",
    "ConvexHull3D = jimport('sc.fiji.snt.analysis.ConvexHull3D')\n",
    "MouseLightLoader = jimport('sc.fiji.snt.io.MouseLightLoader')\n",
    "NodeStatistics = jimport('sc.fiji.snt.analysis.NodeStatistics')\n",
    "PointInImage = jimport('sc.fiji.snt.util.PointInImage')\n",
    "Tree = jimport('sc.fiji.snt.Tree')\n",
    "TreeStatistics = jimport('sc.fiji.snt.analysis.TreeStatistics')\n",
    "Viewer2D = jimport('sc.fiji.snt.viewer.Viewer2D')\n",
    "Viewer3D = jimport('sc.fiji.snt.viewer.Viewer3D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define two support functions: one to download the axonal arbor of a MouseLight neuron, the other to detect the brain area that is the most innervated by its axon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_axon(id_string):\n",
    "    \"\"\"Fetchs an axonal arbor from the MouseLight database by ID\"\"\"\n",
    "    loader = MouseLightLoader(id_string)\n",
    "    if not loader.isDatabaseAvailable():\n",
    "        print(\"Could not connect to ML database\", \"Error\")\n",
    "        return null\n",
    "    if not loader.idExists():\n",
    "        print(\"Somewhow the specified id was not found\", \"Error\")\n",
    "        return null\n",
    "    # Extract the axon sub-tree\n",
    "    return loader.getTree(\"axon\")\n",
    "\n",
    "\n",
    "def get_compartment_terminals(tree):\n",
    "    \"\"\"Finds the AllenCompartment containing the largest number \n",
    "    of axon terminal nodes and returns a collection containing \n",
    "    these nodes as well as the id of the relevant AllenCompartment\"\"\"\n",
    "    \n",
    "    # Use TreeStatistics to extract the terminal nodes from the Tree.\n",
    "    # Instantiate a NodeStatistics instance and retrieve a list of the endpoints for\n",
    "    # each target brain region (a BrainAnnotation) in a dictionary, where the keys are\n",
    "    # the brain annotations. Since this neuron was fetched from the MouseLight database,\n",
    "    # the annotations are instances of the AllenCompartment Class\n",
    "    # https://morphonets.github.io/SNT/sc/fiji/snt/annotation/BrainAnnotation.html\n",
    "    tips = TreeStatistics(tree).getTips()\n",
    "    node_stats = NodeStatistics(tips)\n",
    "    compartment_dict = node_stats.getAnnotatedNodes()\n",
    "\n",
    "    # Get the compartment containing the maximum number of axon terminals\n",
    "    max_compartment = max(compartment_dict, key= lambda x: len(compartment_dict[x]))\n",
    "    # Get the associated list of terminals.\n",
    "    compartment_tips = compartment_dict[max_compartment]\n",
    "    \n",
    "    return compartment_tips, max_compartment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AA1044 (axon) : 2736 terminals\n"
     ]
    }
   ],
   "source": [
    "# Load the reconstruction from the MouseLight database, fetching just the axon\n",
    "tree_axon = get_axon('AA1044')\n",
    "print(tree_axon.getLabel(), \":\", len(TreeStatistics(tree_axon).getTips()), \"terminals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2735 terminals in Caudoputamen\n"
     ]
    }
   ],
   "source": [
    "# Get the compartment with the maximum number of axon terminals\n",
    "axon_terminals, compartment = get_compartment_terminals(tree_axon)\n",
    "print(str(len(axon_terminals)) + \" terminals in \" + str(compartment.name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant hemisphere of Caudoputamen: right\n"
     ]
    }
   ],
   "source": [
    "# We can get the dominant hemi-half of the target compartment using AllenUtils\n",
    "axon_terminals_coords = [[t.getX(), t.getY(), t.getZ()] for t in axon_terminals]\n",
    "centroid = np.mean(axon_terminals_coords, axis=0)\n",
    "hemisphere = \"left\" if AllenUtils.isLeftHemisphere(centroid[0], centroid[1], centroid[2]) else \"right\"\n",
    "print(f\"Dominant hemisphere of {compartment.name()}: \" + hemisphere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D Convex hull area: 1184262.158257923\n",
      "2D Convex hull perimeter: 4177.58198853087\n"
     ]
    }
   ],
   "source": [
    "# Now compute the convex hulls\n",
    "# If we compute a 2D convex hull over a 3D Tree, z coordinates are ignored\n",
    "axon_hull_2D = ConvexHull2D(axon_terminals)\n",
    "# We have to call compute() to generate the hull\n",
    "axon_hull_2D.compute()\n",
    "# size corresponds to volume in 3D, area in 2D\n",
    "# boundarySize corresponds to area in 3D, perimeter in 2D\n",
    "print(\"2D Convex hull area: \" + str(axon_hull_2D.size()))\n",
    "print(\"2D Convex hull perimeter: \" + str(axon_hull_2D.boundarySize()))\n",
    "viewer2d = Viewer2D(ij.getContext())\n",
    "viewer2d.add(tree_axon)\n",
    "viewer2d.addPolygon(axon_hull_2D.getPolygon(), \"Convex Hull 2D Projection\")\n",
    "viewer2d.show()\n",
    "\n",
    "# from IPython.display import Image, display\n",
    "# display(Image(filename=r\"./images/convexhull2D.png\",  width=500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/convexhull2d.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D Convex hull volume: 584596671.2776475\n",
      "3D Convex hull area: 3868120.0732214046\n"
     ]
    }
   ],
   "source": [
    "axon_hull_3D = ConvexHull3D(axon_terminals)\n",
    "axon_hull_3D.compute()\n",
    "print(\"3D Convex hull volume: \" + str(axon_hull_3D.size()))\n",
    "print(\"3D Convex hull area: \" + str(axon_hull_3D.boundarySize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of volume occupied by the convex hull of the axon terminals with respect to the right Caudoputamen [CP] 4.51%\n"
     ]
    }
   ],
   "source": [
    "# Get the OBJMesh which represents the AllenCompartment instance.\n",
    "# Most meshes have pre-computed volumes (via surface integrals) associated with them.\n",
    "# However, certain meshes (e.g., third ventricle) are not watertight,\n",
    "# which precludes a direct volume calculation. \n",
    "# Still, it is possible to approximate the volume of these compartments\n",
    "# using the convex hull computed by Viewer3D.\n",
    "# https://morphonets.github.io/SNT/sc/fiji/snt/viewer/OBJMesh.html\n",
    "obj_mesh = compartment.getMesh()\n",
    "\n",
    "# Now compare the volumes of the 3D convex hull and the compartment mesh\n",
    "# Since this compartment mesh is composed of both hemi-halves, we can approximate\n",
    "# the volume of one hemi-half by dividing the total mesh volume by 2 (assuming perfect symmetry).\n",
    "print(\"Percentage of volume occupied by the convex hull of \"\n",
    "      \"the axon terminals with respect to the {} {} {:0.2f}%\"\n",
    "      .format(hemisphere, compartment, (axon_hull_3D.size() / (0.5 * obj_mesh.getVolume())) * 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we may begin adding the computed objects to SNT's Viewer3D.\n",
    "# Viewer3D has a script-friendly 'add' method which accepts a variety of differnent objects,\n",
    "# e.g., Tree, AbstractDrawable, OBJMesh, etc...\n",
    "viewer = Viewer3D(ij.getContext())\n",
    "viewer.add(tree_axon)\n",
    "\n",
    "# Add the compartment mesh, which contains both left and right nuclei.\n",
    "viewer.add(obj_mesh)\n",
    "\n",
    "# Construct a drawable for Viewer3D from the ImageJ Mesh\n",
    "# https://javadoc.scijava.org/ImageJ/net/imagej/mesh/Mesh.html\n",
    "annotation = Annotation3D(\n",
    "    axon_hull_3D.getMesh(),\n",
    "    f\"Convex hull of axom terminals within {hemisphere} {compartment.name()}\"\n",
    ")\n",
    "annotation.setColor(\"orange\", 95) # transparency (%)\n",
    "viewer.add(annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we can visualize all our hard work!\n",
    "viewer.show()\n",
    "viewer.setAnimationEnabled(True)\n",
    "\n",
    "# To embed a snapshot in this notebook\n",
    "# snapshot_path = os.getcwd() + '/images/convexhull.png'\n",
    "# viewer.saveSnapshot(snapshot_path)\n",
    "# from IPython.display import Image, display\n",
    "# display(Image(filename=snapshot_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/convexhull.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a bonus, let's estimate the principal components of the covariance on the point cloud given by the axon terminals and annotate the resulting eigenvectors as line segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, subtract the mean from the points.\n",
    "points = np.copy(axon_terminals_coords)\n",
    "points -= centroid\n",
    "# Compute the eigenvalues and eigenvectors of the covariance matrix.\n",
    "e_values, e_vectors = np.linalg.eig(np.cov(points.transpose()))\n",
    "\n",
    "# Construct the line segments using the eigenvectors.\n",
    "viewer.setAnimationEnabled(False)\n",
    "viewer.setSceneUpdatesEnabled(False)\n",
    "for i in range(e_vectors.shape[1]):\n",
    "    # The line segments will originate at the centroid of the terminals.\n",
    "    end = centroid + ((np.sqrt(e_values[i]) * 10) * e_vectors[:, i])\n",
    "    line_segment = [PointInImage(centroid[0], centroid[1], centroid[2]), PointInImage(end[0], end[1], end[2])]\n",
    "    # Viewer3D supports adding annotations of various types, and allows customization of \n",
    "    # their visual properties.\n",
    "    # https://morphonets.github.io/SNT/sc/fiji/snt/viewer/Annotation3D.html\n",
    "    annot = viewer.annotateLine(line_segment, \"component {}\".format(i))\n",
    "    annot.setColor(\"white\", 10)\n",
    "    annot.setSize(20)\n",
    "\n",
    "viewer.setSceneUpdatesEnabled(True)\n",
    "viewer.updateView()\n",
    "\n",
    "# from IPython.display import Image, display\n",
    "# display(Image(filename=r\"./images/convexhull-PCA.png\",  width=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/convexhullpca.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
